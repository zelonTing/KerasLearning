{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习是什么，怎么来的，理论基础是什么，为了解决什么问题。\n",
    "机器学习：机器学习是研究如何通过计算手段，利用经验改善系统自身的性能，在计算机上从数据中产生模型。其理论基础有概率论、统计学、逼近论、凸分析、算法复杂理论。\n",
    "主要为了解决从数据中学习规律和模式，以应用在新的数据上做预测任务，这些任务的所需的规则比较复杂，传统的方法难以解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习分类：\n",
    "有监督的学习：是指所有训练的模型，根据数据的真实标签，对模型参数不断的进行调整，从而得到一个更好的性能模型。\n",
    "无监督的学习：在训练模型的时候，对没有标签的数据集进行学习，得到这个数据集的规律、规则。\n",
    "半监督学习：是在训练时，数据中同时有未标记和标记的数据，来进行模式识别的工作训练。减少工作量，提高准确性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有监督的学习：\n",
    "按任务类型分：回归、分类、聚类、降维 生成模型与判别模型\n",
    "回归：主要是针对预测目标数值，其目标值为连续的数值。\n",
    "给定由d个属性描述的示例x={x1，x2，……，xn}，其中xi是x在第i个属性上的取值，线性模型通过属性的线性组合来进行预测函数。\n",
    "$$ f(x) = \\omega^Tx + b$$\n",
    "其中，$$\\omega = \\{\\omega_1;\\omega_2;...,\\omega_n\\}$$\n",
    "\n",
    "分类：对离散型随机变量建模或预测的监督学习方法。\n",
    "\n",
    "聚类：聚类就是对大量未知标注的数据集，按数据内在的相似性将数据集划分为多个类别，使类别内的数据相似度较大而类别间的数据相似度较小。是无监督的分类方式。\n",
    "\n",
    "降维：试图压缩维度，并尽可能地保留分布信息。我们可以将其视为数据压缩，或者特征选择。\n",
    "\n",
    "生成模型：估计的是联合概率分布，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型：P(Y|X)= P(X,Y)/ P(X)。生成方法关心的是给定输入x产生输出y的生成关系。\n",
    "\n",
    "判别模型：估计的是条件概率分布，有数据直接学得决策函数P(X)或者条件概率分布P(Y|X)作为预测的模型。\n",
    "判别式方法关心的是给定输入X，应该预测什么样的输出Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念\n",
    "机器学习方法三要素：模型，策略，算法。\n",
    "\n",
    "模型：机器学习的结果，预测函数。\n",
    "\n",
    "策略：模型学习过程中所用的方法，策略。\n",
    "损失函数\n",
    "\n",
    "算法：使在模型学习过程中，所使用的计算方法，最优的方法。\n",
    "梯度下降法、牛顿法、拟牛顿法\n",
    "\n",
    "模型评估指标：\n",
    "R2：线性回归决定系数。\n",
    "RMSE：均方根误差。\n",
    "accuracy：观测值与真值的接近程度。\n",
    "precision：符合一定的计量要求，使误差保持在规定极限以内的测量仪器的等别、级别。\n",
    "recall：从数据库内检出的相关的信息量与总量的比率。\n",
    "F1：用来衡量二分类（或多任务二分类）模型精确度的一种指标。它同时兼顾了分类模型的准确率和召回率。F1分数可以看作是模型准确率和召回率的一种加权平均，它的最大值是1，最小值是0，值越大意味着模型越好。\n",
    "ROC：是反映敏感性和特异性连续变量的综合指标,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大(AUC area  under roc curve)，诊断准确性越高。\n",
    "AUC：是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率，就是AUC值。\n",
    "\n",
    "Confusion Matrix：每一列代表了预测类别 ，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别 ，每一行的数据总数表示该类别的数据实例的数目。\n",
    "\n",
    "复杂度度量：\n",
    "偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据。\n",
    "方差：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散。\n",
    "过拟合：学习时选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测得很好，对未知数据预测的很差的现象。\n",
    "欠拟合：学习时没有对数据中包含的规律从分的学习。\n",
    "结构风险：为了缓解数据集过小而导致的过拟合现象，其等价于正则化，本质上反应的是模型的复杂度。认为经验风险越小，参数越多，模型越复杂，因此引入对模型复杂度的惩罚机制。\n",
    "经验风险：对训练集中的所有样本点损失函数的平均最小化。经验风险越小说明模型f(X)对训练集的拟合程度越好\n",
    "泛化能力：机器学习算法对新鲜样本的适应能力。\n",
    "正则化：为了减小测试误差的行为(有时候会增加训练误差)\n",
    "模型选择：\n",
    "交叉验证：重复的使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。\n",
    "采样：数据采样就是对随机现象的模拟，根据给定的概率分布从而模拟一个随机事件。\n",
    "特征处理：\n",
    "归一化/标准化：归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为标量。 比较常用的有线性归一化，0均值归一化，以及其他数学函数演变而来的归一化方法。\n",
    "离散化：将连续的数据离散化，主要用于分类。\n",
    "one-hot编码：又称为一位有效编码，主要是采用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候只有一位有效。\n",
    "模型调优：\n",
    "网格搜索寻优：\n",
    "随机搜索寻优："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
